# ğŸ—ï¸ LLM Pool Architecture

## System Overview

The LLM Pool is a smart orchestration layer that sits between your application and multiple LLM models, providing intelligent routing, caching, and ensemble strategies.

## Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ HTTP POST /v1/infer
       â”‚ {task, prompt, strategy}
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LLM Pool Service                 â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. HTTP/gRPC Server               â”‚ â”‚
â”‚  â”‚     - Parse request                â”‚ â”‚
â”‚  â”‚     - Extract task & strategy      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚               â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  2. Orchestrator                   â”‚ â”‚
â”‚  â”‚     - Validate request             â”‚ â”‚
â”‚  â”‚     - Check cache                  â”‚ â”‚
â”‚  â”‚     - Select providers for task    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚               â”‚                          â”‚
â”‚               â”‚ Cache miss?              â”‚
â”‚               â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  3. Ensemble Engine                â”‚ â”‚
â”‚  â”‚                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Strategy: FASTEST            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Fire first provider        â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Hedge after 300ms          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Return first response      â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Strategy: VOTING             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Query all providers        â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Compare responses          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Pick consensus             â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Strategy: JUDGE              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Get multiple candidates    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Use judge model to select  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ - Return best                â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚               â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  4. Provider Pool                  â”‚ â”‚
â”‚  â”‚     - Route to Ollama              â”‚ â”‚
â”‚  â”‚     - Handle timeouts              â”‚ â”‚
â”‚  â”‚     - Track health                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           â”‚           â”‚
    â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phi-3  â”‚  â”‚ Llama  â”‚  â”‚ Gemma  â”‚
â”‚  4B    â”‚  â”‚ 3.1 8B â”‚  â”‚  2 9B  â”‚
â”‚        â”‚  â”‚        â”‚  â”‚        â”‚
â”‚ Fast   â”‚  â”‚ Judge  â”‚  â”‚ Rerank â”‚
â”‚ Light  â”‚  â”‚ Smart  â”‚  â”‚ Refine â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚           â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Ollama     â”‚
        â”‚ localhost:11434â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. API Layer (Server)

**Responsibilities:**
- Accept HTTP and gRPC requests
- Parse and validate input
- Convert between protocols
- Return structured responses

**Files:**
- `src/server/http.rs` - REST API with Axum
- `src/server/grpc.rs` - gRPC with Tonic

**Endpoints:**
- `GET /health` - Service health
- `POST /v1/infer` - Inference request

### 2. Orchestrator

**Responsibilities:**
- Request validation (size, deadline, tokens)
- Cache lookup and storage
- Provider selection based on task
- Strategy determination
- Response formatting

**Files:**
- `src/orchestrator.rs`

**Validation Rules:**
- `deadline_ms` â‰¤ `max_deadline_ms` (1500ms)
- `prompt.len()` â‰¤ `max_prompt_bytes` (16KB)
- `max_tokens` > 0

### 3. Ensemble Engine

**Responsibilities:**
- Execute selected strategy
- Coordinate multiple providers
- Handle failures and fallbacks
- Aggregate results

**Files:**
- `src/ensemble.rs`

**Strategies:**

#### FASTEST
```
Provider A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Response (450ms) âœ“
                                   Return this!
Provider B â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> (800ms) âœ—
                                         Cancelled
```

#### VOTING
```
Provider A â”€â”€> "Option 1" â”€â”€â”
                            â”œâ”€â”€> Compare â”€â”€> "Option 1" (2 votes) âœ“
Provider B â”€â”€> "Option 1" â”€â”€â”¤
                            â”‚
Provider C â”€â”€> "Option 2" â”€â”€â”˜
```

#### JUDGE
```
Provider A â”€â”€> Candidate 1 â”€â”€â”
                             â”œâ”€â”€> Judge Model â”€â”€> "Best: Candidate 2" âœ“
Provider B â”€â”€> Candidate 2 â”€â”€â”¤
                             â”‚
Provider C â”€â”€> Candidate 3 â”€â”€â”˜
```

### 4. Provider Pool

**Responsibilities:**
- Manage provider instances
- Route requests to Ollama
- Health monitoring
- Timeout handling

**Files:**
- `src/providers/mod.rs` - Pool management
- `src/providers/ollama.rs` - Ollama client

**Provider Configuration:**
```toml
[[providers]]
name = "ollama-phi3-mini"
model = "phi3:mini"
tasks = ["expand_queries", "enrich_metadata"]
weight = 0.6
```

### 5. Cache Layer

**Responsibilities:**
- Store inference results
- Generate cache keys
- Manage TTL
- Eviction policy

**Files:**
- `src/cache.rs`

**Cache Key:**
```
SHA256(task + prompt + max_tokens)
```

**Example:**
```
task: "expand_queries"
prompt: "Generate terms for ambient videos"
max_tokens: 256
â†’ Key: "a3f5c8d9e2b1..."
â†’ TTL: 900 seconds (15 min)
```

## Data Flow Example

### Request: Expand Queries (FASTEST)

```
1. Client Request
   POST /v1/infer
   {
     "task": "expand_queries",
     "prompt": "ambient cinematic",
     "max_tokens": 256
   }

2. Orchestrator
   âœ“ Validate: OK
   âœ“ Cache: MISS
   âœ“ Providers: [phi3-mini, llama31-8b]
   âœ“ Strategy: FASTEST (from config)

3. Ensemble (FASTEST)
   â†’ Fire phi3-mini immediately
   â†’ Set hedge timer: 300ms
   â†’ phi3-mini responds in 450ms
   â†’ Return phi3-mini result
   â†’ Cancel hedge

4. Cache
   â†’ Store result with TTL 900s

5. Response
   {
     "request_id": "uuid",
     "content": "{\"must_include\": [...]}",
     "winner_model": "phi3:mini",
     "duration_ms": 450,
     "from_cache": false,
     "strategy_used": "FASTEST"
   }
```

### Request: Judge (JUDGE Strategy)

```
1. Client Request
   POST /v1/infer
   {
     "task": "judge",
     "prompt": "Select best: [candidates...]",
     "strategy": "JUDGE"
   }

2. Orchestrator
   âœ“ Providers: [llama31-8b, gemma2-9b]
   âœ“ Strategy: JUDGE (explicit)

3. Ensemble (JUDGE)
   â†’ Query llama31-8b & gemma2-9b in parallel
   â†’ Get 2 candidates
   â†’ Use llama31-8b as judge
   â†’ Judge selects best candidate
   â†’ Return winner

4. Response
   {
     "winner_model": "llama3.1:8b",
     "duration_ms": 1150,
     "strategy_used": "JUDGE",
     "models_queried": ["llama3.1:8b", "gemma2:9b"]
   }
```

## Task-to-Model Mapping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task                â”‚ Strategy     â”‚ Models          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ expand_queries      â”‚ FASTEST      â”‚ Phi-3 â†’ Llama   â”‚
â”‚ enrich_metadata     â”‚ FASTEST      â”‚ Phi-3           â”‚
â”‚ recovery_plan       â”‚ FASTEST      â”‚ Phi-3 â†’ Llama   â”‚
â”‚ judge               â”‚ JUDGE        â”‚ Llama (judge)   â”‚
â”‚ rerank_candidates   â”‚ JUDGE        â”‚ Llama + Gemma   â”‚
â”‚ site_tactics        â”‚ JUDGE        â”‚ Llama + Gemma   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration Hot-Reload

```
1. User edits llm-pool.toml
   [ensemble]
   default_strategy = "VOTING"  # Changed from FASTEST

2. File watcher detects change
   notify crate â†’ event

3. Config loader
   â†’ Parse new TOML
   â†’ Validate structure
   â†’ If valid: apply
   â†’ If invalid: log error, keep old config

4. Service continues
   â†’ No restart needed
   â†’ Active requests complete with old config
   â†’ New requests use new config
```

## Error Handling

```
Request
  â”‚
  â”œâ”€> Validation Error
  â”‚   â””â”€> 400 Bad Request
  â”‚
  â”œâ”€> Cache Error
  â”‚   â””â”€> Log warning, continue without cache
  â”‚
  â”œâ”€> All Providers Fail
  â”‚   â””â”€> 503 Service Unavailable
  â”‚
  â”œâ”€> Deadline Exceeded
  â”‚   â””â”€> 504 Gateway Timeout
  â”‚
  â””â”€> Success
      â””â”€> 200 OK with Answer
```

## Performance Characteristics

### Latency Budget (1500ms total)

```
HTTP Parsing:        ~5ms
Validation:         ~1ms
Cache Lookup:       ~2ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Subtotal:           ~8ms

Provider Call:    450-1200ms  (depends on model)
Ensemble Logic:    ~10-50ms   (depends on strategy)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Inference:       460-1250ms

Response Format:    ~5ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:          473-1263ms  âœ“ Under 1500ms budget
```

### Memory Usage

```
Service Base:        ~50MB
Phi-3 Mini (4B):   ~2.5GB
Llama 3.1 (8B):    ~5.0GB
Gemma 2 (9B):      ~5.5GB
Cache:             ~100MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total (3 models): ~13.1GB

Recommendation: 16GB RAM minimum, 32GB ideal
```

## Scalability Considerations

### Current (Single Instance)
- Handles: ~10-20 concurrent requests
- Bottleneck: Model inference time
- Throughput: ~5-10 req/sec

### Future (Horizontal Scaling)
- Multiple LLM Pool instances
- Load balancer in front
- Shared Redis cache
- Provider pool per instance

### Future (Vertical Scaling)
- More GPU memory â†’ larger models
- More CPU cores â†’ more concurrent requests
- SSD â†’ faster model loading

## Security Layers (Planned)

```
Request
  â”‚
  â”œâ”€> 1. TLS/HTTPS
  â”‚      â””â”€> Encrypted transport
  â”‚
  â”œâ”€> 2. API Gateway
  â”‚      â””â”€> Rate limiting, WAF
  â”‚
  â”œâ”€> 3. HMAC/JWT Auth
  â”‚      â””â”€> Verify signature
  â”‚
  â”œâ”€> 4. Tenant Isolation
  â”‚      â””â”€> Separate quotas
  â”‚
  â””â”€> 5. LLM Pool
         â””â”€> Process request
```

## Monitoring Points

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metrics to Track                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Request rate (req/sec)                â”‚
â”‚ â€¢ Latency (p50, p95, p99)               â”‚
â”‚ â€¢ Cache hit rate (%)                    â”‚
â”‚ â€¢ Provider health (up/down)             â”‚
â”‚ â€¢ Strategy usage (FASTEST/VOTING/...)   â”‚
â”‚ â€¢ Model selection frequency             â”‚
â”‚ â€¢ Error rate (%)                        â”‚
â”‚ â€¢ Timeout rate (%)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary

The LLM Pool architecture provides:

1. **Flexibility**: Multiple strategies for different use cases
2. **Performance**: Caching and smart routing
3. **Reliability**: Health checks and fallbacks
4. **Observability**: Structured logging and metrics
5. **Maintainability**: Hot-reload and modular design

For implementation details, see the source code in `src/`.
